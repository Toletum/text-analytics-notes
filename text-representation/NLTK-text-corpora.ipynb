{
 "metadata": {
  "name": "NLTK-text-corpora"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from nltk.corpus import gutenberg", 
      "gutenberg.fileids()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stderr", 
       "text": [
        "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.", 
        "  VisibleDeprecationWarning)"
       ]
      }, 
      {
       "output_type": "pyout", 
       "prompt_number": 1, 
       "text": [
        "[u'austen-emma.txt',", 
        " u'austen-persuasion.txt',", 
        " u'austen-sense.txt',", 
        " u'bible-kjv.txt',", 
        " u'blake-poems.txt',", 
        " u'bryant-stories.txt',", 
        " u'burgess-busterbrown.txt',", 
        " u'carroll-alice.txt',", 
        " u'chesterton-ball.txt',", 
        " u'chesterton-brown.txt',", 
        " u'chesterton-thursday.txt',", 
        " u'edgeworth-parents.txt',", 
        " u'melville-moby_dick.txt',", 
        " u'milton-paradise.txt',", 
        " u'shakespeare-caesar.txt',", 
        " u'shakespeare-hamlet.txt',", 
        " u'shakespeare-macbeth.txt',", 
        " u'whitman-leaves.txt']"
       ]
      }
     ], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "emma = gutenberg.words('austen-emma.txt')", 
      "len(emma)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 2, 
       "text": [
        "192427"
       ]
      }
     ], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "for fileid in gutenberg.fileids():", 
      "    num_chars = len(gutenberg.raw(fileid))       # access raw contents ", 
      "    num_words = len(gutenberg.words(fileid))     # access as a list of tokens ", 
      "    num_sents = len(gutenberg.sents(fileid)) # access as a list of sentences ( list os list of words)", 
      "    num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))", 
      "    print int(num_chars/num_words), int(num_words/num_sents), int(num_words/num_vocab), fileid "
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "4 24 26 austen-emma.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 26 16 austen-persuasion.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 28 22 austen-sense.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 33 79 bible-kjv.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 19 5 blake-poems.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 19 14 bryant-stories.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 17 12 burgess-busterbrown.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 20 12 carroll-alice.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 20 11 chesterton-ball.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 22 11 chesterton-brown.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 18 10 chesterton-thursday.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 20 24 edgeworth-parents.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 25 15 melville-moby_dick.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 52 10 milton-paradise.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 11 8 shakespeare-caesar.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 12 7 shakespeare-hamlet.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 12 6 shakespeare-macbeth.txt", 
        "4"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " 36 12 whitman-leaves.txt"
       ]
      }
     ], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Conditional Distribution of words"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import nltk", 
      "from nltk.corpus import inaugural", 
      "", 
      "cfd = nltk.ConditionalFreqDist()", 
      "for fileid in inaugural.fileids():", 
      "    for w in inaugural.words(fileid):", 
      "        for target in ['america', 'citizen']:", 
      "            if w.lower().startswith(target):", 
      "                cfd[target][fileid[:4]] += 1", 
      "", 
      "cfd.plot()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# Usando el inicializador y for-comprehensions", 
      "cfd = nltk.ConditionalFreqDist(", 
      "                 (target,fileid[:4])", 
      "                 for fileid in inaugural.fileids()", 
      "                 for w in inaugural.words(fileid)", 
      "                 for target in ['america', 'citizen']", 
      "                 if w.lower().startswith(target))", 
      "                ", 
      "cfd.plot()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from nltk.corpus import brown", 
      "", 
      "cfd = nltk.ConditionalFreqDist((genre, word)", 
      "              for genre in ['news','romance']", 
      "              for word in brown.words(categories=genre))", 
      "cfd.conditions()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 21, 
       "text": [
        "['romance', 'news']"
       ]
      }
     ], 
     "prompt_number": 21
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print(cfd['news'])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "<FreqDist with 14394 samples and 100554 outcomes>"
       ]
      }
     ], 
     "prompt_number": 22
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "cfd['romance'].most_common(20)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 24, 
       "text": [
        "[(u',', 3899),", 
        " (u'.', 3736),", 
        " (u'the', 2758),", 
        " (u'and', 1776),", 
        " (u'to', 1502),", 
        " (u'a', 1335),", 
        " (u'of', 1186),", 
        " (u'``', 1045),", 
        " (u\"''\", 1044),", 
        " (u'was', 993),", 
        " (u'I', 951),", 
        " (u'in', 875),", 
        " (u'he', 702),", 
        " (u'had', 692),", 
        " (u'?', 690),", 
        " (u'her', 651),", 
        " (u'that', 583),", 
        " (u'it', 573),", 
        " (u'his', 559),", 
        " (u'she', 496)]"
       ]
      }
     ], 
     "prompt_number": 24
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "cfd.tabulate(samples=['could', 'can', 'would'])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "        could  can would ", 
        "   news   86   93  244 ", 
        "romance  193   74  244 "
       ]
      }
     ], 
     "prompt_number": 31
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "# Generating Random Text with Bigrams"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text = nltk.corpus.genesis.words('english-kjv.txt')", 
      "bigrams = nltk.bigrams(text)", 
      "cfd = nltk.ConditionalFreqDist(bigrams)", 
      "cfd['living']"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 34, 
       "text": [
        "FreqDist({u'creature': 7, u'thing': 4, u'substance': 2, u',': 1, u'.': 1, u'soul': 1})"
       ]
      }
     ], 
     "prompt_number": 34
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "def generate_model(cfdist, word, num=15):", 
      "    for i in range(num):", 
      "        print word,", 
      "        word = cfdist[word].max()", 
      "generate_model(cfd,'living')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "living creature that he said , and the land of the land of the land"
       ]
      }
     ], 
     "prompt_number": 39
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "# Stopwords and Lexicons"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from nltk.corpus import stopwords", 
      "stopwords.words('english')[0:10]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 42, 
       "text": [
        "[u'i',", 
        " u'me',", 
        " u'my',", 
        " u'myself',", 
        " u'we',", 
        " u'our',", 
        " u'ours',", 
        " u'ourselves',", 
        " u'you',", 
        " u'your']"
       ]
      }
     ], 
     "prompt_number": 42
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "# Wordnet"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from nltk.corpus import wordnet as wn ", 
      "wn.synsets('motorcar')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 45, 
       "text": [
        "[Synset('car.n.01')]"
       ]
      }
     ], 
     "prompt_number": 45
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').lemma_names()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 50, 
       "text": [
        "[u'car', u'auto', u'automobile', u'machine', u'motorcar']"
       ]
      }
     ], 
     "prompt_number": 50
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').definition()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 52, 
       "text": [
        "u'a motor vehicle with four wheels; usually propelled by an internal combustion engine'"
       ]
      }
     ], 
     "prompt_number": 52
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').examples()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 56, 
       "text": [
        "[u'he needs a car to get to work']"
       ]
      }
     ], 
     "prompt_number": 56
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').lemmas()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 58, 
       "text": [
        "[Lemma('car.n.01.car'),", 
        " Lemma('car.n.01.auto'),", 
        " Lemma('car.n.01.automobile'),", 
        " Lemma('car.n.01.machine'),", 
        " Lemma('car.n.01.motorcar')]"
       ]
      }
     ], 
     "prompt_number": 58
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synsets('car')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 60, 
       "text": [
        "[Synset('car.n.01'),", 
        " Synset('car.n.02'),", 
        " Synset('car.n.03'),", 
        " Synset('car.n.04'),", 
        " Synset('cable_car.n.01')]"
       ]
      }
     ], 
     "prompt_number": 60
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "for synset in wn.synsets('car'):", 
      "   print synset.lemma_names()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "[u'car', u'auto', u'automobile', u'machine', u'motorcar']", 
        "[u'car', u'railcar', u'railway_car', u'railroad_car']", 
        "[u'car', u'gondola']", 
        "[u'car', u'elevator_car']", 
        "[u'cable_car', u'car']"
       ]
      }
     ], 
     "prompt_number": 64
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Lexical relations"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').hyponyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 69, 
       "text": [
        "[Synset('ambulance.n.01'),", 
        " Synset('beach_wagon.n.01'),", 
        " Synset('bus.n.04'),", 
        " Synset('cab.n.03'),", 
        " Synset('compact.n.03'),", 
        " Synset('convertible.n.01'),", 
        " Synset('coupe.n.01'),", 
        " Synset('cruiser.n.01'),", 
        " Synset('electric.n.01'),", 
        " Synset('gas_guzzler.n.01'),", 
        " Synset('hardtop.n.01'),", 
        " Synset('hatchback.n.01'),", 
        " Synset('horseless_carriage.n.01'),", 
        " Synset('hot_rod.n.01'),", 
        " Synset('jeep.n.01'),", 
        " Synset('limousine.n.01'),", 
        " Synset('loaner.n.02'),", 
        " Synset('minicar.n.01'),", 
        " Synset('minivan.n.01'),", 
        " Synset('model_t.n.01'),", 
        " Synset('pace_car.n.01'),", 
        " Synset('racer.n.02'),", 
        " Synset('roadster.n.01'),", 
        " Synset('sedan.n.01'),", 
        " Synset('sport_utility.n.01'),", 
        " Synset('sports_car.n.01'),", 
        " Synset('stanley_steamer.n.01'),", 
        " Synset('stock_car.n.01'),", 
        " Synset('subcompact.n.01'),", 
        " Synset('touring_car.n.01'),", 
        " Synset('used-car.n.01')]"
       ]
      }
     ], 
     "prompt_number": 69
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').hypernyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 72, 
       "text": [
        "[Synset('motor_vehicle.n.01')]"
       ]
      }
     ], 
     "prompt_number": 72
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').hypernym_paths()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 75, 
       "text": [
        "[[Synset('entity.n.01'),", 
        "  Synset('physical_entity.n.01'),", 
        "  Synset('object.n.01'),", 
        "  Synset('whole.n.02'),", 
        "  Synset('artifact.n.01'),", 
        "  Synset('instrumentality.n.03'),", 
        "  Synset('container.n.01'),", 
        "  Synset('wheeled_vehicle.n.01'),", 
        "  Synset('self-propelled_vehicle.n.01'),", 
        "  Synset('motor_vehicle.n.01'),", 
        "  Synset('car.n.01')],", 
        " [Synset('entity.n.01'),", 
        "  Synset('physical_entity.n.01'),", 
        "  Synset('object.n.01'),", 
        "  Synset('whole.n.02'),", 
        "  Synset('artifact.n.01'),", 
        "  Synset('instrumentality.n.03'),", 
        "  Synset('conveyance.n.03'),", 
        "  Synset('vehicle.n.01'),", 
        "  Synset('wheeled_vehicle.n.01'),", 
        "  Synset('self-propelled_vehicle.n.01'),", 
        "  Synset('motor_vehicle.n.01'),", 
        "  Synset('car.n.01')]]"
       ]
      }
     ], 
     "prompt_number": 75
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('car.n.01').root_hypernyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 80, 
       "text": [
        "[Synset('entity.n.01')]"
       ]
      }
     ], 
     "prompt_number": 80
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('tree.n.01').part_meronyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 82, 
       "text": [
        "[Synset('burl.n.02'),", 
        " Synset('crown.n.07'),", 
        " Synset('limb.n.02'),", 
        " Synset('stump.n.01'),", 
        " Synset('trunk.n.01')]"
       ]
      }
     ], 
     "prompt_number": 82
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('tree.n.01').substance_meronyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 84, 
       "text": [
        "[Synset('heartwood.n.01'), Synset('sapwood.n.01')]"
       ]
      }
     ], 
     "prompt_number": 84
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('tree.n.01').member_holonyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 86, 
       "text": [
        "[Synset('forest.n.01')]"
       ]
      }
     ], 
     "prompt_number": 86
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('walk.v.01').entailments()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 87, 
       "text": [
        "[Synset('step.v.01')]"
       ]
      }
     ], 
     "prompt_number": 87
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('tease.v.03').entailments()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 90, 
       "text": [
        "[Synset('arouse.v.07'), Synset('disappoint.v.01')]"
       ]
      }
     ], 
     "prompt_number": 90
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.lemma('horizontal.a.01.horizontal').antonyms()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 92, 
       "text": [
        "[Lemma('inclined.a.02.inclined'), Lemma('vertical.a.01.vertical')]"
       ]
      }
     ], 
     "prompt_number": 92
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "# Semantic similarity"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "right = wn.synset('right_whale.n.01')", 
      "orca = wn.synset('orca.n.01')", 
      "minke = wn.synset('minke_whale.n.01')", 
      "tortoise = wn.synset('tortoise.n.01')", 
      "novel = wn.synset('novel.n.01')"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 94
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "right.lowest_common_hypernyms(minke)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 97, 
       "text": [
        "[Synset('baleen_whale.n.01')]"
       ]
      }
     ], 
     "prompt_number": 97
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "right.lowest_common_hypernyms(tortoise)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 100, 
       "text": [
        "[Synset('vertebrate.n.01')]"
       ]
      }
     ], 
     "prompt_number": 100
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "right.lowest_common_hypernyms(novel)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 103, 
       "text": [
        "[Synset('entity.n.01')]"
       ]
      }
     ], 
     "prompt_number": 103
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "wn.synset('whale.n.01').min_depth()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 106, 
       "text": [
        "5"
       ]
      }
     ], 
     "prompt_number": 106
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "right.path_similarity(minke)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 109, 
       "text": [
        "0.25"
       ]
      }
     ], 
     "prompt_number": 109
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "right.path_similarity(tortoise)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 110, 
       "text": [
        "0.07692307692307693"
       ]
      }
     ], 
     "prompt_number": 110
    }
   ]
  }
 ]
}