{
 "metadata": {
  "name": "NLTK-intro-stats"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "# Inspeccionando colecciones de textos", 
      "", 
      "Ejemplos de uso de la librer\u00eda NLTK para investigar una coleccion de textos"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from  nltk.book import *"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "*** Introductory Examples for the NLTK Book ***", 
        "Loading text1, ..., text9 and sent1, ..., sent9", 
        "Type the name of the text or sentence to view it.", 
        "Type: 'texts()' or 'sents()' to list the materials.", 
        "text1:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " Moby Dick by Herman Melville 1851", 
        "text2:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " Sense and Sensibility by Jane Austen 1811", 
        "text3:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " The Book of Genesis", 
        "text4:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " Inaugural Address Corpus", 
        "text5:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " Chat Corpus", 
        "text6: Monty Python and the Holy Grail", 
        "text7:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " Wall Street Journal", 
        "text8: Personals Corpus", 
        "text9:"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " The Man Who Was Thursday by G . K . Chesterton 1908"
       ]
      }, 
      {
       "output_type": "stream", 
       "stream": "stderr", 
       "text": [
        "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.", 
        "  VisibleDeprecationWarning)"
       ]
      }
     ], 
     "prompt_number": 1
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "NLTK proporciona una clase Text para explorar el contenido de los textos. SE trata como una lista de palabra"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "text1?"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 2
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text1[11] # Palabra en la posicion 11 "
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 3, 
       "text": [
        "u'Supplied'"
       ]
      }
     ], 
     "prompt_number": 3
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text1.index('Supplied') # Dada una palabra encontrar la primera posici\u00f3n en la que aparece"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 4, 
       "text": [
        "11"
       ]
      }
     ], 
     "prompt_number": 4
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Explorar el contexto de uso de una palabra (KWIC - Keyword in context) ", 
      "", 
      "Permite conocer el uso que se hace de una palabra dentro de un documento. "
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text1.concordance('monstrous')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Displaying 11 of 11 matches:", 
        "ong the former , one was of a most monstrous size . ... This came towards us , ", 
        "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r", 
        "ll over with a heathenish array of monstrous clubs and spears . Some were thick", 
        "d as you gazed , and wondered what monstrous cannibal and savage could ever hav", 
        "that has survived the flood ; most monstrous and most mountainous ! That Himmal", 
        "they might scout at Moby Dick as a monstrous fable , or still worse and more de", 
        "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l", 
        "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly", 
        "ere to enter upon those still more monstrous stories of them which are to be fo", 
        "ght have been rummaged out of this monstrous cabinet there is no telling . But ", 
        "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u"
       ]
      }
     ], 
     "prompt_number": 5
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Similitud por distribucion (Distributional similarity)", 
      "", 
      "Podemos identificar palabras similares porque comparten contextos parecidos con otras palabras."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text1.similar('monstrous')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "imperial subtly impalpable pitiable curious abundant perilous", 
        "trustworthy untoward singular lamentable few determined maddens", 
        "horrible tyrannical lazy mystifying christian exasperate"
       ]
      }
     ], 
     "prompt_number": 6
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text2.similar('monstrous')"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "very exceedingly so heartily a great good amazingly as sweet", 
        "remarkably extremely vast"
       ]
      }
     ], 
     "prompt_number": 7
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "Podemos incluso consultar cu\u00e1les son algunos de los contextos que comparten dos o m\u00e1s palabras. "
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text1.common_contexts(['monstrous','horrible'])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "most_and"
       ]
      }
     ], 
     "prompt_number": 8
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text2.common_contexts(['monstrous','very'])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "a_pretty is_pretty a_lucky am_glad be_glad"
       ]
      }
     ], 
     "prompt_number": 9
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Estad\u00edsticas de un texto"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "len(text4) # Longitud de un texto"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 10, 
       "text": [
        "145735"
       ]
      }
     ], 
     "prompt_number": 10
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "sorted(set(text4))[0:10] # Conjunto de palabras (tokens) en un texto ordenanas por orden alfab\u00e9tico"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 11, 
       "text": [
        "[u'!', u'\"', u'\";', u'\"?', u'$', u\"'\", u'(', u')', u'),', u',']"
       ]
      }
     ], 
     "prompt_number": 11
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "sorted(set(text4))[100:110] # Primero se ordenan los simbolos de puntuacion"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 12, 
       "text": [
        "[u'AS',", 
        " u'Abandonment',", 
        " u'Abhorring',", 
        " u'About',", 
        " u'Above',", 
        " u'Abraham',", 
        " u'Abroad',", 
        " u'Accept',", 
        " u'Across',", 
        " u'Act']"
       ]
      }
     ], 
     "prompt_number": 12
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "len(set(text4)) # N\u00famero de palabras \u00fanicos (types) en un texto "
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 13, 
       "text": [
        "9754"
       ]
      }
     ], 
     "prompt_number": 13
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "len(set([token.lower() for token in text4])) # Normalizamos tokens - mayusculas "
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 14, 
       "text": [
        "9070"
       ]
      }
     ], 
     "prompt_number": 14
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "len(set([token.lower() for token in text4 if token.isalpha()])) # Eliminamos los signos de puntuaci\u00f3n"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 15, 
       "text": [
        "8968"
       ]
      }
     ], 
     "prompt_number": 15
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from __future__ import division ", 
      "len(text4)/ len(set(text4)) # Media de veces que se usa cada palabra - aproximaci\u00f3n un poco burda"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 16, 
       "text": [
        "14.941049825712529"
       ]
      }
     ], 
     "prompt_number": 16
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text4.count('America') # Numero de veces que aparece una palabra - \"Frecuencia\""
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 17, 
       "text": [
        "192"
       ]
      }
     ], 
     "prompt_number": 17
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "fdist = FreqDist(text4) # Distribuci\u00f3n de los terminos \u00fanicos (types) - Distribuci\u00f3n de frecuencias", 
      "fdist.tabulate(20)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        " the   of    ,  and    .   to   in    a  our that   be   is   we  for   by   it which have  not   as ", 
        "9281 6970 6840 4991 4676 4311 2527 2134 1905 1688 1460 1403 1141 1075 1036 1011 1002  994  916  888 "
       ]
      }
     ], 
     "prompt_number": 18
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "fdist['America'] # \"Frecuencia\" de una palabra - tf (term frequency) en IR"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 19, 
       "text": [
        "192"
       ]
      }
     ], 
     "prompt_number": 19
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "fdist.freq('America') # Frecuencia relativa de una palabra - tf/N"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 20, 
       "text": [
        "0.0013174597728754247"
       ]
      }
     ], 
     "prompt_number": 20
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "fdist.plot(50, cumulative = True) # Distribuci\u00f3n acumulada de las 50 palabras m\u00e1s frecuentes. ", 
      "# Se trata de casi el 50% de los tokens del texto. Zipf law, stopwords"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 21
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "fdist.hapaxes()[0:10] # Hapax Legomena - palabras que aprecen mencionadas solo una vez - frecuencia = 1"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 22, 
       "text": [
        "[u'writings',", 
        " u'Does',", 
        " u'hanging',", 
        " u'granting',", 
        " u'refunding',", 
        " u'impoverishment',", 
        " u'sinking',", 
        " u'shielding',", 
        " u'pages',", 
        " u'appropriation']"
       ]
      }
     ], 
     "prompt_number": 22
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "sorted([w for w in set(text4) if len(w) > 5 and fdist[w] > 5])[0:10] # Terminos con m\u00e1s de 5 letras y una frecuencia superior a 5"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 23, 
       "text": [
        "[u'Administration',", 
        " u'Almighty',", 
        " u'America',", 
        " u'American',", 
        " u'Americans',", 
        " u'Atlantic',", 
        " u'Because',", 
        " u'Before',", 
        " u'Beyond',", 
        " u'British']"
       ]
      }
     ], 
     "prompt_number": 23
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "text4.dispersion_plot(['citizens', 'democracy','freedom','duties','America']) # Distribucion de las palabras a lo largo de un texto"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 24
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "lendist = FreqDist([len(w) for w in text4]) # Frecuencia de las longitudes de las palabras", 
      "lendist.tabulate()"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "   3    2    4    1    5    6    7    8    9   10   11   12   13   14   15   16   17 ", 
        "28426 27111 18158 16269 12885 10604 9827 7168 5591 4690 2442 1411  615  399   79   50   10 "
       ]
      }
     ], 
     "prompt_number": 25
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "lendist.freq(3)"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 26, 
       "text": [
        "0.19505266408206676"
       ]
      }
     ], 
     "prompt_number": 26
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Terminos multipalabra (Collocations) y Bigramas (Bigrams)"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "b = bigrams(text1) # Secuencias de 2 palabras tal y como aparecen en el texto", 
      "list(b)[0:20]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 27, 
       "text": [
        "[(u'[', u'Moby'),", 
        " (u'Moby', u'Dick'),", 
        " (u'Dick', u'by'),", 
        " (u'by', u'Herman'),", 
        " (u'Herman', u'Melville'),", 
        " (u'Melville', u'1851'),", 
        " (u'1851', u']'),", 
        " (u']', u'ETYMOLOGY'),", 
        " (u'ETYMOLOGY', u'.'),", 
        " (u'.', u'('),", 
        " (u'(', u'Supplied'),", 
        " (u'Supplied', u'by'),", 
        " (u'by', u'a'),", 
        " (u'a', u'Late'),", 
        " (u'Late', u'Consumptive'),", 
        " (u'Consumptive', u'Usher'),", 
        " (u'Usher', u'to'),", 
        " (u'to', u'a'),", 
        " (u'a', u'Grammar'),", 
        " (u'Grammar', u'School')]"
       ]
      }
     ], 
     "prompt_number": 27
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "text4.collocations() # Collocation - secuencia de palabras que aparecen juntas con una frecuencia superior a lo habitual"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "United States; fellow citizens; four years; years ago; Federal", 
        "Government; General Government; American people; Vice President; Old", 
        "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;", 
        "God bless; every citizen; Indian tribes; public debt; one another;", 
        "foreign nations; political parties"
       ]
      }
     ], 
     "prompt_number": 28
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "text4.collocations?"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 29
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "# Operaciones con cadenas (Python)"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "[w for w in set(text4) if w.endswith('able')][0:10] # Palabras que acaban en sufijo"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 30, 
       "text": [
        "[u'Honorable',", 
        " u'preferable',", 
        " u'admirable',", 
        " u'colorable',", 
        " u'memorable',", 
        " u'respectable',", 
        " u'understandable',", 
        " u'amicable',", 
        " u'navigable',", 
        " u'unfavorable']"
       ]
      }
     ], 
     "prompt_number": 30
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "[w for w in set(text4) if 'lg' in w]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 31, 
       "text": [
        "[u'pilgrimage',", 
        " u'promulgation',", 
        " u'indulge',", 
        " u'Indulging',", 
        " u'amalgamated',", 
        " u'indulgence',", 
        " u'indulged']"
       ]
      }
     ], 
     "prompt_number": 31
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "[w for w in set(text4) if w.istitle()][0:10]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 32, 
       "text": [
        "[u'Does',", 
        " u'Until',", 
        " u'Western',", 
        " u'Less',", 
        " u'Xthough',", 
        " u'Honorable',", 
        " u'Church',", 
        " u'Opportunism',", 
        " u'Isles',", 
        " u'Compared']"
       ]
      }
     ], 
     "prompt_number": 32
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 32
    }
   ]
  }
 ]
}