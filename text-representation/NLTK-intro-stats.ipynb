{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspeccionando colecciones de textos\n",
    "\n",
    "Ejemplos de uso de la librería NLTK para investigar una coleccion de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from  nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK proporciona una clase Text para explorar el contenido de los textos. SE trata como una lista de palabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Supplied'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[11] # Palabra en la posicion 11 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.index('Supplied') # Dada una palabra encontrar la primera posición en la que aparece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorar el contexto de uso de una palabra (KWIC - Keyword in context) \n",
    "\n",
    "Permite conocer el uso que se hace de una palabra dentro de un documento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u"
     ]
    }
   ],
   "source": [
    "text1.concordance('monstrous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud por distribucion (Distributional similarity)\n",
    "\n",
    "Podemos identificar palabras similares porque comparten contextos parecidos con otras palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imperial subtly impalpable pitiable curious abundant perilous\n",
      "trustworthy untoward singular lamentable few determined maddens\n",
      "horrible tyrannical lazy mystifying christian exasperate"
     ]
    }
   ],
   "source": [
    "text1.similar('monstrous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very exceedingly so heartily a great good amazingly as sweet\n",
      "remarkably extremely vast"
     ]
    }
   ],
   "source": [
    "text2.similar('monstrous')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos incluso consultar cuáles son algunos de los contextos que comparten dos o más palabras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most_and"
     ]
    }
   ],
   "source": [
    "text1.common_contexts(['monstrous','horrible'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty is_pretty a_lucky am_glad be_glad"
     ]
    }
   ],
   "source": [
    "text2.common_contexts(['monstrous','very'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estadísticas de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text4) # Longitud de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'!', u'\"', u'\";', u'\"?', u'$', u\"'\", u'(', u')', u'),', u',']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text4))[0:10] # Conjunto de palabras (tokens) en un texto ordenanas por orden alfabético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AS',\n",
       " u'Abandonment',\n",
       " u'Abhorring',\n",
       " u'About',\n",
       " u'Above',\n",
       " u'Abraham',\n",
       " u'Abroad',\n",
       " u'Accept',\n",
       " u'Across',\n",
       " u'Act']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(text4))[100:110] # Primero se ordenan los simbolos de puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9754"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text4)) # Número de palabras únicos (types) en un texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9070"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([token.lower() for token in text4])) # Normalizamos tokens - mayusculas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8968"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([token.lower() for token in text4 if token.isalpha()])) # Eliminamos los signos de puntuación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.941049825712529"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division \n",
    "len(text4)/ len(set(text4)) # Media de veces que se usa cada palabra - aproximación un poco burda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text4.count('America') # Numero de veces que aparece una palabra - \"Frecuencia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the   of    ,  and    .   to   in    a  our that   be   is   we  for   by   it which have  not   as \n",
      "9281 6970 6840 4991 4676 4311 2527 2134 1905 1688 1460 1403 1141 1075 1036 1011 1002  994  916  888 "
     ]
    }
   ],
   "source": [
    "fdist = FreqDist(text4) # Distribución de los terminos únicos (types) - Distribución de frecuencias\n",
    "fdist.tabulate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist['America'] # \"Frecuencia\" de una palabra - tf (term frequency) en IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0013174597728754247"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.freq('America') # Frecuencia relativa de una palabra - tf/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist.plot(50, cumulative = True) # Distribución acumulada de las 50 palabras más frecuentes. \n",
    "# Se trata de casi el 50% de los tokens del texto. Zipf law, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'writings',\n",
       " u'Does',\n",
       " u'hanging',\n",
       " u'granting',\n",
       " u'refunding',\n",
       " u'impoverishment',\n",
       " u'sinking',\n",
       " u'shielding',\n",
       " u'pages',\n",
       " u'appropriation']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.hapaxes()[0:10] # Hapax Legomena - palabras que aprecen mencionadas solo una vez - frecuencia = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Administration',\n",
       " u'Almighty',\n",
       " u'America',\n",
       " u'American',\n",
       " u'Americans',\n",
       " u'Atlantic',\n",
       " u'Because',\n",
       " u'Before',\n",
       " u'Beyond',\n",
       " u'British']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([w for w in set(text4) if len(w) > 5 and fdist[w] > 5])[0:10] # Terminos con más de 5 letras y una frecuencia superior a 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text4.dispersion_plot(['citizens', 'democracy','freedom','duties','America']) # Distribucion de las palabras a lo largo de un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3    2    4    1    5    6    7    8    9   10   11   12   13   14   15   16   17 \n",
      "28426 27111 18158 16269 12885 10604 9827 7168 5591 4690 2442 1411  615  399   79   50   10 "
     ]
    }
   ],
   "source": [
    "lendist = FreqDist([len(w) for w in text4]) # Frecuencia de las longitudes de las palabras\n",
    "lendist.tabulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19505266408206676"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lendist.freq(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminos multipalabra (Collocations) y Bigramas (Bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'[', u'Moby'),\n",
       " (u'Moby', u'Dick'),\n",
       " (u'Dick', u'by'),\n",
       " (u'by', u'Herman'),\n",
       " (u'Herman', u'Melville'),\n",
       " (u'Melville', u'1851'),\n",
       " (u'1851', u']'),\n",
       " (u']', u'ETYMOLOGY'),\n",
       " (u'ETYMOLOGY', u'.'),\n",
       " (u'.', u'('),\n",
       " (u'(', u'Supplied'),\n",
       " (u'Supplied', u'by'),\n",
       " (u'by', u'a'),\n",
       " (u'a', u'Late'),\n",
       " (u'Late', u'Consumptive'),\n",
       " (u'Consumptive', u'Usher'),\n",
       " (u'Usher', u'to'),\n",
       " (u'to', u'a'),\n",
       " (u'a', u'Grammar'),\n",
       " (u'Grammar', u'School')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = bigrams(text1) # Secuencias de 2 palabras tal y como aparecen en el texto\n",
    "list(b)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; four years; years ago; Federal\n",
      "Government; General Government; American people; Vice President; Old\n",
      "World; Almighty God; Fellow citizens; Chief Magistrate; Chief Justice;\n",
      "God bless; every citizen; Indian tribes; public debt; one another;\n",
      "foreign nations; political parties"
     ]
    }
   ],
   "source": [
    "text4.collocations() # Collocation - secuencia de palabras que aparecen juntas con una frecuencia superior a lo habitual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text4.collocations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones con cadenas (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Honorable',\n",
       " u'preferable',\n",
       " u'admirable',\n",
       " u'colorable',\n",
       " u'memorable',\n",
       " u'respectable',\n",
       " u'understandable',\n",
       " u'amicable',\n",
       " u'navigable',\n",
       " u'unfavorable']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in set(text4) if w.endswith('able')][0:10] # Palabras que acaban en sufijo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'pilgrimage',\n",
       " u'promulgation',\n",
       " u'indulge',\n",
       " u'Indulging',\n",
       " u'amalgamated',\n",
       " u'indulgence',\n",
       " u'indulged']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in set(text4) if 'lg' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Does',\n",
       " u'Until',\n",
       " u'Western',\n",
       " u'Less',\n",
       " u'Xthough',\n",
       " u'Honorable',\n",
       " u'Church',\n",
       " u'Opportunism',\n",
       " u'Isles',\n",
       " u'Compared']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in set(text4) if w.istitle()][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
