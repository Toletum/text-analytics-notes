{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representación de documentos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "César de Pablo Sánchez\n",
    "\n",
    "@zdepablo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Índice\n",
    "\n",
    "  - Modelo de bolsa de palabras\n",
    "  - Preprocesamiento\n",
    "    - Tokenización\n",
    "    - Stopwords\n",
    "    - Stemming \n",
    "    - Lematización\n",
    "    - N-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Cómo representar un documento?\n",
    "\n",
    "<img src=\"../spark/img/ModelTraining.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Cómo representar un documento?\n",
    "\n",
    " - Multiples posibilidades en función de la tarea a resolver\n",
    " - Creciente complejidad \n",
    "    - Bolsa de palabras (terminos) (Bag of Words)\n",
    "    - Vector de palabras (TF-IDF) \n",
    "    - Generación de características ad-hoc \n",
    "    - etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelos de Bolsa de Palabras\n",
    " \n",
    "<img src=\"../img/MatrizTerminosDocumentos.jpg\" width=\"800\">\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modelo de Bolsa de Palabras - características de la representación\n",
    "\n",
    "  - Sencillo \n",
    "  - Aplicaciones: Text Classification, Text Clustering, Ad-hoc Information Retrieval, Lexical Semantics\n",
    "\n",
    "  - Cada documento se representa como un conjunto de palabras\n",
    "     - El orden no se tiene en cuenta\n",
    "     - Interpretación extrema de la semántica composicional – el significado de una frase es la composición de los significados individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Ejemplo:\n",
    "\n",
    "  - I see what I eat\n",
    "  - I eat what I see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenización "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "     is no basis for a system of government.  Supreme executive power derives from \n",
    "     a mandate from the masses, not from some farcical aquatic ceremony.  \n",
    "     It's a pity that I that don't have an example \"\"\"\n",
    "    \n",
    "tokens = nltk.word_tokenize(raw)\n",
    "print tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenización\n",
    "\n",
    "Se divide el texto en unidades lingüísticas mínimas: tokens\n",
    "  - Baseline: Espacio o signos de puntuación como separador de tokens\n",
    "  - Guiones (ex-wife), comillas (O'Donnell, it's) , signos de puntuación (…)\n",
    "  - Normalización:\n",
    "      - paso a minúsculas\n",
    "      - eliminar acentos y diacríticos\n",
    "      - normalizar la representación de símbolos especiales:\n",
    "      - anti-war, antiwar\n",
    "      - USA, U.S.A.\n",
    "      - eliminar puntuación\n",
    "  - Otros problemas prácticos: URLs, emails, cifras, fechas, @usuario, etc.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribución de los tokens\n",
    "\n",
    "<img src=\"https://finnaarupnielsen.files.wordpress.com/2013/10/brownzipf.png?w=487\" width=\"600\">\n",
    "\n",
    "\n",
    "Imagen y código (Finn Nielsen): https://finnaarupnielsen.wordpress.com/2013/10/22/zipf-plot-for-word-counts-in-brown-corpus/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Palabras de parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopset = set(stopwords.words('english'))\n",
    "\n",
    "print stopset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Palabras de parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "filtered_tokens = [word for word in tokens if word not in stopset]\n",
    "print filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "stems = [porter.stem(t) for t in tokens]\n",
    "print stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lancaster = nltk.LancasterStemmer()\n",
    "stems = [lancaster.stem(t) for t in tokens]\n",
    "print stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lemmatización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(t) for t in tokens]\n",
    "print lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Operaciones sobre cadenas en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lowercase_tokens = [token.lower() for token in tokens]\n",
    "\n",
    "print lowercase_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[w for w in tokens if w.endswith('ing')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigrams = nltk.bigrams(tokens)\n",
    "\n",
    "\n",
    "print [b for b in bigrams]\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
