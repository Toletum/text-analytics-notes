{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduccion a \n",
    "\n",
    "#Spark Mllib y Mahout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science - Flujo de trabajo\n",
    "\n",
    " - Construccion de los modelos \n",
    "    - Exploracion \n",
    "    - Construcción de características \n",
    "    - Entrenamiento de modelos\n",
    "    - Evaluación y seleccion del modelo \n",
    " - Puesta en produccion de modelos \n",
    "    - Optimización de las características \n",
    "    - Desplegar modelo/predicciones \n",
    "    - Evaluacion en vivo \n",
    "    - Mantenimiento, versionado, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science - Flujo de trabajo\n",
    "\n",
    "<img src=\"./img/DataScience-Flujo.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science con Big Data - arquitectura \"típica\"\n",
    "\n",
    "<img src=\"./img/Arquitectura-DS-Server.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tareas básicas de aprendizaje automático\n",
    "\n",
    "- Regresión\n",
    "- Clasificación  \n",
    "- Descubrimiento de grupos (Clustering) \n",
    "- Reducción de dimensiones \n",
    "- Recomendación\n",
    "- Reglas de asociacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "<img src=\"./img/ModelTraining.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "<img src=\"./img/ModelTraining-2.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion cruzada\n",
    "\n",
    "<img src=\"./img/ModelTraining-3.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de *stacks* para Data Science\n",
    "\n",
    "<img src=\"./img/DS-stacks.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando ML - Distribuir el entrenamiento de los modelos\n",
    "\n",
    "<img src=\"./img/ScalingML-1.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando ML - Distribuir la selección del modelo\n",
    "\n",
    "<img src=\"./img/ScalingML-2.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando ML -  Algoritmos apropiados para escalar - Batch vs Online\n",
    "\n",
    "<img src=\"./img/ScalingML-3.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando ML - Adaptar algoritmos para distribución de datos\n",
    "\n",
    "<img src=\"./img/ScalingML-4.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalando ML* - Model averaging\n",
    "\n",
    "<img src=\"./img/ScalingML-5.jpg\" width=\"800\">\n",
    "\n",
    "* No propiamente distribución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puesta en producción\n",
    "\n",
    " - Cada aplicación puede suponer un escenario diferente\n",
    " - Ejemplos: \n",
    "    - Clasificador de noticias: (online) - etiqueta una nueva noticia según se ingesta \n",
    "    - Recomendador de música (Spotify) (offline) - semanalmente genera una lista de canciones recomendadas. \n",
    "    \n",
    "- Es necesario optimizar: \n",
    "    - fase de prediccion del algoritmo de aprendizaje \n",
    "    - generación de características\n",
    "    - \"interfaz\" entre aplicacion y sistema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark MLlib\n",
    "\n",
    " - Biblioteca de aprendizaje automático sobre Spark\n",
    " - Desarrollada en Scala\n",
    " - API Disponible para Scala, Java, Python (R)\n",
    " - Última version 1.6.0 (Marzo 2016) \n",
    " - Activamente desarrollada\n",
    " - Proporciona principalmente: \n",
    "      - algoritmos de ML\n",
    "      - estructuras de datos escalables\n",
    "      - algoritmos de optimización\n",
    " - Algunas utilidades estadísticas y para evaluacion\n",
    " - No es ideal para poner en produccion online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLLIB - Algoritmos\n",
    "  - Esdatística descriptiva \n",
    "  - Support Vector Machines (C,R) \n",
    "  - Regresion lineal (R) \n",
    "  - Regresion Lógistica (C) \n",
    "  - Naive Bayes (C) \n",
    "  - Árboles de decision (C,R) y *emsembles*: Random Forests, Gradient Boostes Trees\n",
    "  - Isotonic regression \n",
    "  - Alternating least squares (Rec) \n",
    "  - k-means (Clus) - tradicional, bisecting, streaming \n",
    "  - Gaussian mixture (Clus)\n",
    "  - Power iteration clustering (Clus)\n",
    "  - Latent Dirichlet allocation (Clus)\n",
    "  - Singular value decomposition (DR)\n",
    "  - Principal component analysis (DR)\n",
    "  - FP-growth (A) \n",
    "  - Association rules (A)\n",
    "  - PrefixSpan (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLlib - Estructuras de datos\n",
    " - RDD (Resilient Distributed Datasets - Spark) \n",
    " - Vector \n",
    " - Matrix \n",
    " - Dataframes (Spark) - desde 1.5 aprox. estables\n",
    " - Dataset - desde 1.6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector (local) \n",
    " - vector de doubles almacenado en una máquina local\n",
    " - indizado por enteros empezando en 0 \n",
    " \n",
    "#### DenseVector - array de double \n",
    "   [1.0, 0.0, 3.0]\n",
    "   \n",
    "#### SparseVector -  para vectores donde muchos valores son cero \n",
    "   (3, [0,2] , [1.0, 3.0] )  \n",
    "\n",
    "#### LabeledPoint - Vector + Label "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix (Local) \n",
    " - vector de doubles almacenado en una máquina local\n",
    " - indizado por filas y columnas, enteros empezando en 0 \n",
    "\n",
    "### DenseMatrix\n",
    "\n",
    "### SparseMatrix \n",
    "  - CSC (Compressed Sparse Column)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Matrix\n",
    " - vector de doubles almacenado en uno o varios RDD\n",
    " - indizado por filas y columnas, longs empezando en 0 \n",
    " - convertir una matriz a otro formato puede ser costoso - global shuffle\n",
    " \n",
    "### RowMatrix  \n",
    " - una coleccion de vectores en un RDD \n",
    " - asume un numero de columnas razonablemente pequeño para operar/comunicar \n",
    "\n",
    "### Indexed RowMatrix\n",
    " - IndexedRowMatrix - indices de fila para hacer joins \n",
    "\n",
    "### CoordinateMatrix\n",
    "  - Coordinate list (row, column, value) en un RDD \n",
    "  \n",
    "### BlockMatrix \n",
    "  -  MatrixBlocks en un RDD (int,int, MatrixBlock) \n",
    "  - multiply using map reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe (Spark + spark.ml)\n",
    " - estructura usada en Spark SQL \n",
    " - coleccion distribuida de datos organizada en columnas con nonbres\n",
    " - tabla relacional o dataframe R/Python \n",
    " - se puede construir desde CSV, tablas de Hive o DBs o RDDs\n",
    " - Disponible en Scala, Java, Python o R \n",
    " - no es tipado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    " - nuevo en 1.6 \n",
    " - Coleccion distribuida\n",
    " - Permite las operaciones de un Dataframe \n",
    " - Es tipado como los RDD\n",
    " - Algunas operaciones como el filtrado, ordenacion o hashing se pueden realizar sin deserializar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    " - Combinar y estandarizar la aplicacion de transaformaciones y multiples algoritmos \n",
    " - Construido sobre los Dataframes\n",
    "\n",
    "### Transformer \n",
    "  - un algoritmo que transforma un DataFrame en otro DataFrame\n",
    "    - ML algorithm : DataFrame con caracteristicas en DataFrame con predicciones \n",
    "    - Fetature transformation \n",
    "\n",
    "### Estimator \n",
    "\n",
    "### Pipelines \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Mahout\n",
    "\n",
    " - Conjunto de librerias de aprendizaje automático escalable\n",
    " - Proyecto creado en 2008 como parte de Apache Lucene \n",
    " - Desarrollado inicialmente en Java \n",
    " - Ultima version: 0.11.2 - Marzo de 2016  \n",
    " - Actualmente es un poco cajon de sastre:\n",
    "    - Algoritmos en memoria - Recomendadores por filtrado colaborativo\n",
    "    - Algoritmos Map/Reduce \n",
    "    - Algoritmos en memoria distribuida (Spark, H20, Flink)\n",
    "    - Entorno de algebra matricial en memoria distribuida (Samsara)  \n",
    "    \n",
    "https://mahout.apache.org/users/basics/algorithms.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mahout MapReduce\n",
    " - Implementaciones escalables de algoritmos de clasificacion, clustering y recomendacion\n",
    " - Usan HDFS (SequenceFile) como origen, destino y almacenamiento intermedio de datos \n",
    " - Algoritmos escalables: \n",
    "    - Clasificacion: NaiveBayes, RandomForest \n",
    "    - Clustering : K-means, Spectral Clustering  \n",
    "    - Recomendación : Item-based, SVD \n",
    " - Utilidades para extraer características - principalmente de colecciones de texto\n",
    " - Exponen como utilidades en linea de comandos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Mahout) MapReduce\n",
    "\n",
    " - **Principal ventaja**: escalan a grandes grandes volumenes de datos, mucho mayor que la memoria disponible\n",
    " - **Principal problema**: muchos algoritmos son iterativos, requieren escribir a disco cada iteración \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo K-means\n",
    "\n",
    "<img src=\"./img/Kmeans-MapReduce-1.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Map Reduce \n",
    "\n",
    "<img src=\"./img/Kmeans-MapReduce-2.jpg\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
