{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Categorización de textos\n",
    "\n",
    "## Análisis de sentimiento en reseñas de cine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Análisis de sentimiento\n",
    "\n",
    "* __Objetivo__: Clasificar reseñas de películas como aquellas que valoran de forma positiva o negativa una película\n",
    "* Ejemplo sencillo de hacer análisis de la opinión como una tarea de clasificación o de categorización de documentos.\n",
    "* __Corpus__:  Movie Reviews (Pang and Lee 2002) - usado en los primeros trabajos de de análisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cargar Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print movie_reviews.readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspección del corpus (I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Mostrar las categorias: clasificación binaria entre textos positivos y negativos\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## Obtener los identificadores de fichero - podemos ver los datos en el directorio nltk_data \n",
    "## o inspeccionar mediante las utilidades de la clase CorpusReader\n",
    "\n",
    "files = movie_reviews.fileids()\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspeccionar un documento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files[100]  ## Nombre del fichero con el id = 100 - la carpeta indica la categoría\n",
    "## Los ficheros con cada review se representan como una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_reviews.categories(files[1300]) # ¿Cual es la categoría del documento? \n",
    "## categories(list) acepta una lista de ids de documentos y obtinene el conjunto de categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Cómo están etiquetados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_reviews.fileids('neg') # Obten todos los documentos etiquetados como una categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ¿Cuantos ejemplos hay de cada una de las clases? \n",
    "\n",
    "print \"Ejemplos positivos: %s\" % len(movie_reviews.fileids('pos'))\n",
    "print \"Ejemplos negativos: %s\" % len(movie_reviews.fileids('neg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contenido del documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = movie_reviews.words(files[1]) # Recordad que la representación por defecto de nltk es como una lista de tokens\n",
    "\n",
    "print \" \".join(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ¿Qué características podemos usar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecciona varios documentos y trata de leer las reviews:\n",
    " * ¿Que características tiene el texto respecto a tokenización? \n",
    " * Identifica que tipo de características podrían ser interesantes para la tareas \n",
    " * ¿Son generalizables? \n",
    " * Identifica problemas, pero sin quedarte en lo anecdótico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribución de frecuencias en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "all_words.most_common() # Mostrar la lista de palabras más comunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Usando un clasificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Seleccion de características: Todas las palabras\n",
    "\n",
    "Inicialmente seleccionamos todos los tokens de un texto como características de nuestro clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implementamos la extraccion de características como una función que se aplica a la lista de tokens de un documento\n",
    "# NLTK nos permite representar las caracxterísticas como un diccionario\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "\n",
    "word_feats(['How', 'are', 'you','?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Representación de los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conjunto de instancias - documento\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "# Vectores de características\n",
    "negfeatures = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') \n",
    "               for f in negids]\n",
    "posfeatures = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') \n",
    "               for f in posids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posfeatures[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Generación de conjuntos de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utilizamos \n",
    "#  - 3/4 partes de los documentos de cada clase para entrenamiento\n",
    "#  - 1/4 part para evaluación \n",
    "negcutoff = len(negfeatures)*3/4\n",
    "poscutoff = len(posfeatures)*3/4\n",
    "\n",
    "trainfeats = negfeatures[:negcutoff] + posfeatures[:poscutoff]\n",
    "testfeats = negfeatures[negcutoff:] + posfeatures[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), \n",
    "                                                       len(testfeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainfeats[751][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ¿Qué pinta tienen los vectores de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print trainfeats[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entrenamiento del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Usamos el clasificador NaiveBayes de NLTK - Bernouilli NB (binario)\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluación del clasificador (I)\n",
    "\n",
    "Como primera aproximación usamos la medida de **Accuracy** - Porcentaje de acierto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluación del clasificador: Discusión\n",
    "\n",
    "* ¿Es adecuada para este dataset? \n",
    "* ¿Es adecuada para la tarea de análisis de sentimiento? \n",
    "* ¿Y si tuviesemos varias clases de sentimiento: positivo, negativo, neutro?\n",
    "* ¿Y si los ejemplos estuviesen desbalanceados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mostrar las características más informativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluación del clasificador (II)\n",
    "\n",
    "Otras medidas de evaluación: Precision, Recall (Cobertura) y su combinación la medida F\n",
    "\n",
    "\\begin{equation*}\n",
    "Precision = \\frac{tp}{tp +fp}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "Recall = \\frac{tp}{tp +fn}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluación del clasificador (III)\n",
    "\n",
    "F es la media armónica entre la precision y la cobertura\n",
    "\n",
    "\\begin{equation*}\n",
    "F = 2 · \\frac{Precision · Recall}{Precision + Recall}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluación del clasificador (IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "\n",
    "for i, (feats, label) in enumerate(testfeats):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    " \n",
    "print 'pos precision:', nltk.metrics.precision(refsets['pos'], testsets['pos'])\n",
    "print 'pos recall:', nltk.metrics.recall(refsets['pos'], testsets['pos'])\n",
    "print 'pos F-measure:', nltk.metrics.f_measure(refsets['pos'], testsets['pos'])\n",
    "print '---------'\n",
    "print 'neg precision:', nltk.metrics.precision(refsets['neg'], testsets['neg'])\n",
    "print 'neg recall:', nltk.metrics.recall(refsets['neg'], testsets['neg'])\n",
    "print 'neg F-measure:', nltk.metrics.f_measure(refsets['neg'], testsets['neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discusión\n",
    "\n",
    "* ¿Resultados?\n",
    "* ¿Que se puede mejorar? \n",
    " * Construccion del conjunto de entrenamiento/test \n",
    " * Selección de características\n",
    " * Procesimiento para elegir características - ¿estamos viendo las características de test?\n",
    " * Algoritmos de aprendizaje"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
