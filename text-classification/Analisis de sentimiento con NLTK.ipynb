{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Análisis de sentimiento como clasificación de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo: Clasificar reseñas de películas como aquellas que valoran de forma positiva o negativa una película\n",
    "\n",
    "\n",
    "Ejemplo sencillo de hacer análisis de la opinión como una tarea de clasificación o de categorización de textos. \n",
    "\n",
    "Usaremos el corpus que se uso en uno de los primeros estudios acerca de análisis de sentimiento (movie_reviews) (Pang and Lee 2002) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "print movie_reviews.readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspección del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mostrar las categorias: clasificación binaria entre textos positivos y negativos\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Obtener los identificadores de fichero - podemos ver los datos en el directorio nltk_data \n",
    "## o inspeccionar mediante las utilidades de la clase CorpusReader\n",
    "\n",
    "files = movie_reviews.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files[100]  ## Nombre del fichero con el id = 1000 - la carpeta indica la categoría\n",
    "## Los ficheros con cada review se representan como una lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_reviews.categories(files[0]) # ¿Cual es la categoría del documento? \n",
    "## categories(list) acepta una lista de ids de documentos y obtinene el conjunto de categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_reviews.fileids('pos') # Obten todos los documentos etiquetados como una categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ¿Cuantos ejemplos hay de cada una de las clases? \n",
    "\n",
    "print \"Ejemplos positivos: %s\" % len(movie_reviews.fileids('pos'))\n",
    "print \"Ejemplos negativos: %s\" % len(movie_reviews.fileids('neg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspeccionar algun documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc = movie_reviews.words(files[0]) # Recordad que la representación por defecto de nltk es como una lista de tokens\n",
    "\n",
    "print \" \".join(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecciona varios documentos y trata de leer las reviews:\n",
    " * ¿Que características tiene el texto respecto a tokenización? \n",
    " * Identifica que tipo de características podrían ser interesantes para la tareas \n",
    " * ¿Son generalizables? \n",
    " * Identifica problemas, pero sin quedarse en lo anecdótico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspeccionar las características del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "all_words.most_common() # Mostrar la lista de palabras más comunes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar y evaluar un Clasificador Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccion de características: Todas las palabras\n",
    "\n",
    "Inicialmente seleccionamos todos los tokens de un texto como características de nuestro clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implementamos la extraccion de características como una función que se aplica a la lista de tokens de un documento\n",
    "# NLTK nos permite representar las caracxterísticas como un diccionario\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Conjunto de instancias - documento\n",
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "\n",
    "# Vectores de características\n",
    "negfeatures = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negids]\n",
    "posfeatures = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in posids]\n",
    "\n",
    "# Utilizamos \n",
    "#  - 3/4 partes de los documentos de cada clase para entrenamiento\n",
    "#  - 1/4 part para evaluación \n",
    "negcutoff = len(negfeatures)*3/4\n",
    "poscutoff = len(posfeatures)*3/4\n",
    "\n",
    "trainfeats = negfeatures[:negcutoff] + posfeatures[:poscutoff]\n",
    "testfeats = negfeatures[negcutoff:] + posfeatures[poscutoff:]\n",
    "print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " ¿Qué pinta tienen los vectores de características?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué pinta tienen los vectores de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print trainfeats[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Usamos el clasificador NaiveBayes de NLTK - Bernouilli NB (binario)\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(trainfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del clasificador (1)\n",
    "\n",
    "Como primera aproximación usamos la medida de **Accuracy** - Porcentaje de acierto\n",
    "\n",
    "### Discusion\n",
    "* ¿Es adecuada para este dataset? \n",
    "* ¿Es adecuada para la tarea de análisis de sentimiento? \n",
    "* ¿Y si tuviesemos varias clases de sentimiento: positivo, negativo, neutro?\n",
    "* ¿Y si los ejemplos estuviesen desbalancesados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'accuracy:', nltk.classify.util.accuracy(classifier, testfeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar las características más informativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del clasificador (2)\n",
    "\n",
    "Otras medidas de evaluación: Precision, Recall (Cobertura) y su combinación la medida F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Precision = \\frac{tp}{tp +fp}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "Recall = \\frac{tp}{tp +fn}\n",
    "\\end{equation*}\n",
    "\n",
    "F es la media armónica entre la precision y la cobertura\n",
    "\n",
    "\\begin{equation*}\n",
    "F = 2 · \\frac{Precision · Recall}{Precision + Recall}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "\n",
    "\n",
    "for i, (feats, label) in enumerate(testfeats):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    " \n",
    "print 'pos precision:', nltk.metrics.precision(refsets['pos'], testsets['pos'])\n",
    "print 'pos recall:', nltk.metrics.recall(refsets['pos'], testsets['pos'])\n",
    "print 'pos F-measure:', nltk.metrics.f_measure(refsets['pos'], testsets['pos'])\n",
    "print 'neg precision:', nltk.metrics.precision(refsets['neg'], testsets['neg'])\n",
    "print 'neg recall:', nltk.metrics.recall(refsets['neg'], testsets['neg'])\n",
    "print 'neg F-measure:', nltk.metrics.f_measure(refsets['neg'], testsets['neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discusión\n",
    "\n",
    "* ¿Resultados?\n",
    "* ¿Que se puede mejorar? \n",
    " * Construccion del conjunto de entrenamiento/test \n",
    " * Selección de características\n",
    " * Procesimiento para elegir características - ¿estamos viendo las características de test?\n",
    " * Algoritmos de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
