{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import collections \n",
    "\n",
    "from nltk.corpus import conll2002\n",
    "from sklearn.linear_model import Perceptron\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NamedEntityTagger(nltk.TaggerI):\n",
    "    def __init__(self,train_sents):\n",
    "        train_set=[]\n",
    "        for sentence in train_sents:\n",
    "            untagged_sent = [(word, tag) for (word, tag, ne_tag) in sentence]\n",
    "            history = []\n",
    "            for i, (word, tag, ne_tag) in enumerate(sentence):\n",
    "                featureset = ne_features(untagged_sent, i, history)\n",
    "                train_set.append( (featureset, ne_tag) ) \n",
    "                history.append(ne_tag)\n",
    "        self.classifier =  SklearnClassifier(Perceptron())       \n",
    "        self.classifier.train(train_set)\n",
    "        self.classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "        \n",
    "#        Alternative with sk-learn\n",
    "#        self.classifier =  SklearnClassifier(Perceptron())       \n",
    "#        self.classifier.train(train_set)\n",
    "\n",
    "#        self.classifier = SklearnClassifier(LinearSVC())        \n",
    "#        self.classifier.train(train_set)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def tag(self, sentence):\n",
    "        history = []\n",
    "        for i, (word, tag) in enumerate(sentence):\n",
    "            featureset = ne_features(sentence, i, history)\n",
    "            tag = self.classifier.classify(featureset)\n",
    "            history.append(tag)\n",
    "        return zip(sentence, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(nerctagger, test_sentences):\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "\n",
    "    i = 0\n",
    "    for test_sentence in test_sentences:\n",
    "        tagged_sentence = nerctagger.tag([(word,tag) for (word,tag, ne_tag) in test_sentence])\n",
    "        for ((word,tag,label),(pair,predicted)) in zip(test_sentence,tagged_sentence):\n",
    "            refsets[label].add(i)\n",
    "            testsets[predicted].add(i)\n",
    "            i = i+1\n",
    "\n",
    "    tags = ['B-LOC','I-LOC','B-ORG','I-ORG','B-PER','I-PER']\n",
    "    \n",
    "    (ma_precision, ma_recall, ma_fmeasure) = (0,0,0)\n",
    "    for label_type in tags:\n",
    "        precision = nltk.metrics.precision(refsets[label_type], testsets[label_type])\n",
    "        recall = nltk.metrics.recall(refsets[label_type], testsets[label_type])\n",
    "        fmeasure = nltk.metrics.f_measure(refsets[label_type], testsets[label_type])\n",
    "        print 'precision(%s):' % label_type, precision \n",
    "        print 'recall(%s):' % label_type, recall \n",
    "        print 'F-measure(%s):' % label_type, fmeasure\n",
    "        print '\\n'\n",
    "        ma_precision += precision\n",
    "        ma_recall += recall\n",
    "        ma_fmeasure += fmeasure\n",
    "        \n",
    "        \n",
    "    print \"--------------------------------------------------------------------------------\"\n",
    "    print \"Precision (Ma):\", ma_precision/len(tags)  \n",
    "    print \"Recall (Ma):\", ma_recall/len(tags)\n",
    "    print \"F-measure (Ma):\", ma_fmeasure/len(tags)\n",
    "    print \"--------------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sentences = conll2002.iob_sents('esp.train')\n",
    "test_sentences = conll2002.iob_sents('esp.testa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(B-LOC): 0.607287449393\n",
      "recall(B-LOC): 0.609756097561\n",
      "F-measure(B-LOC): 0.608519269777\n",
      "\n",
      "\n",
      "precision(I-LOC): 0.509345794393\n",
      "recall(I-LOC): 0.323442136499\n",
      "F-measure(I-LOC): 0.395644283122\n",
      "\n",
      "\n",
      "precision(B-ORG): 0.782608695652\n",
      "recall(B-ORG): 0.582352941176\n",
      "F-measure(B-ORG): 0.667790893761\n",
      "\n",
      "\n",
      "precision(I-ORG): 0.496124031008\n",
      "recall(I-ORG): 0.234260614934\n",
      "F-measure(I-ORG): 0.318249627051\n",
      "\n",
      "\n",
      "precision(B-PER): 0.735457063712\n",
      "recall(B-PER): 0.434533551555\n",
      "F-measure(B-PER): 0.546296296296\n",
      "\n",
      "\n",
      "precision(I-PER): 0.580952380952\n",
      "recall(I-PER): 0.284051222352\n",
      "F-measure(I-PER): 0.381548084441\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision (Ma): 0.618629235852\n",
      "Recall (Ma): 0.411399427346\n",
      "F-measure (Ma): 0.486341409075\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def ne_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    return {\"word\": word}\n",
    "\n",
    "nerctagger = NamedEntityTagger(train_sentences)\n",
    "eval(nerctagger, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(B-LOC): 0.740585774059\n",
      "recall(B-LOC): 0.359756097561\n",
      "F-measure(B-LOC): 0.484268125855\n",
      "\n",
      "\n",
      "precision(I-LOC): 0.572413793103\n",
      "recall(I-LOC): 0.246290801187\n",
      "F-measure(I-LOC): 0.344398340249\n",
      "\n",
      "\n",
      "precision(B-ORG): 0.739130434783\n",
      "recall(B-ORG): 0.62\n",
      "F-measure(B-ORG): 0.674344209853\n",
      "\n",
      "\n",
      "precision(I-ORG): 0.561739130435\n",
      "recall(I-ORG): 0.236456808199\n",
      "F-measure(I-ORG): 0.332818134982\n",
      "\n",
      "\n",
      "precision(B-PER): 0.653209109731\n",
      "recall(B-PER): 0.516366612111\n",
      "F-measure(B-PER): 0.576782449726\n",
      "\n",
      "\n",
      "precision(I-PER): 0.207865168539\n",
      "recall(I-PER): 0.559953434226\n",
      "F-measure(I-PER): 0.303183107469\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision (Ma): 0.579157235108\n",
      "Recall (Ma): 0.423137292214\n",
      "F-measure (Ma): 0.452632394689\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def ne_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    return {\"word\": word, \"pos\": pos}\n",
    "\n",
    "nerctagger = NamedEntityTagger(train_sentences)\n",
    "eval(nerctagger, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(B-LOC): 0.392444910808\n",
      "recall(B-LOC): 0.760162601626\n",
      "F-measure(B-LOC): 0.517647058824\n",
      "\n",
      "\n",
      "precision(I-LOC): 0.7\n",
      "recall(I-LOC): 0.290801186944\n",
      "F-measure(I-LOC): 0.410901467505\n",
      "\n",
      "\n",
      "precision(B-ORG): 0.548181818182\n",
      "recall(B-ORG): 0.709411764706\n",
      "F-measure(B-ORG): 0.618461538462\n",
      "\n",
      "\n",
      "precision(I-ORG): 0.565853658537\n",
      "recall(I-ORG): 0.254758418741\n",
      "F-measure(I-ORG): 0.351337708228\n",
      "\n",
      "\n",
      "precision(B-PER): 0.68496849685\n",
      "recall(B-PER): 0.622749590835\n",
      "F-measure(B-PER): 0.652378911273\n",
      "\n",
      "\n",
      "precision(I-PER): 0.398224476855\n",
      "recall(I-PER): 0.731082654249\n",
      "F-measure(I-PER): 0.515599343186\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision (Ma): 0.548278893538\n",
      "Recall (Ma): 0.561494369517\n",
      "F-measure (Ma): 0.511054337913\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def ne_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "    return {\"word\": word, \"pos\": pos, \"prevpos\": prevpos}\n",
    "\n",
    "nerctagger = NamedEntityTagger(train_sentences)\n",
    "eval(nerctagger, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision(B-LOC): 0.487297921478\n",
      "recall(B-LOC): 0.643292682927\n",
      "F-measure(B-LOC): 0.554533508541\n",
      "\n",
      "\n",
      "precision(I-LOC): 0.302845528455\n",
      "recall(I-LOC): 0.442136498516\n",
      "F-measure(I-LOC): 0.359469240048\n",
      "\n",
      "\n",
      "precision(B-ORG): 0.484848484848\n",
      "recall(B-ORG): 0.715294117647\n",
      "F-measure(B-ORG): 0.577946768061\n",
      "\n",
      "\n",
      "precision(I-ORG): 0.431399631676\n",
      "recall(I-ORG): 0.685944363104\n",
      "F-measure(I-ORG): 0.529677784059\n",
      "\n",
      "\n",
      "precision(B-PER): 0.556935817805\n",
      "recall(B-PER): 0.660392798691\n",
      "F-measure(B-PER): 0.604268064395\n",
      "\n",
      "\n",
      "precision(I-PER): 0.617258883249\n",
      "recall(I-PER): 0.707799767171\n",
      "F-measure(I-PER): 0.659436008677\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Precision (Ma): 0.480097711252\n",
      "Recall (Ma): 0.642476704676\n",
      "F-measure (Ma): 0.547555228964\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def ne_features(sentence, i, history):\n",
    "    word, pos = sentence[i]\n",
    "    if i == 0:\n",
    "        prevword, prevpos = \"<START>\", \"<START>\"\n",
    "    else:\n",
    "        prevword, prevpos = sentence[i-1]\n",
    "    if i == 0:\n",
    "        prevtag = \"<START>\"\n",
    "    else:\n",
    "        prevtag = history[i-1]        \n",
    "    return {\"word\": word, \"isAlnum\": word.isalnum(), \"isDigit\": word.isdigit(), \"pos\": pos, \"prevword\": prevword, \"prevpos\": prevpos, \"prevtag\" : prevtag}\n",
    "\n",
    "nerctagger = NamedEntityTagger(train_sentences)\n",
    "eval(nerctagger, test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
